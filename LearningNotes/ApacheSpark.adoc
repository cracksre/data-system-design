= Apache Spark
:idprefix:
:idseparator: -
:sectanchors:
:sectlinks:
:sectnumlevels: 6
:sectnums:
:toc: macro
:toclevels: 6
:toc-title:

toc::[]


Does Spark use a gossip protocol? Why?

. No, Spark does not use a Gossip Protocol.

== Structured Streaming

How to achieve exactly once from Kafka to Kafka for stateless job?

Performance bottleneck
[start=1]
. Tune your Kafka brokers (num.io.threads, num.network.threads)
. Avoid cloud services rate limit.

=== Checkpointing
Checkpoint is to track the progress of a query in persistent storage.


----
aggDF
  .writeStream
  .outputMode("complete")
  .option("checkpointLocation", "path/to/HDFS/dir")  // checkpointing
  .format("memory")
  .start()
----

How does `S3 eventual consistency` affect checkpointing?

To reuse checkpoint, what `can be changed`
[start=1]
. Sinks
. Input/ Output schema (in the absence of stateful operations)
. Triggers
. Transformations
. Spark Versions


To reuse checkpoint, what `cannot be changed`
[start=1]
. Stateful operations
. Output Mode (will work, but semantics of stream has changed)
. Sources

Work-arounds
[start=1]
. Restart stream from scratch
.. use new checkpoint location - avoid S3 eventual consistency
.. partition source tables by date, restart stream from a given data

=== Testing
Best Practices
[start=1]
. Use Spark `StreamTest` harness for unit tests. Use `MemorySource` and `MemorySink` to test business logic.
. Test data dependencies, schema changes upstream can break downstream jobs.

=== Monitoring

==== Push metrics to external services
. Leverage `StreamingQueryListener` API. Push data to metrics store (Cloudwatch, Prometheus).


https://docs.databricks.com/en/structured-streaming/stream-monitoring.html[Example Kafka-to-Kafka StreamingQueryListener event]
[source, jsonlines]
----
{
  "id" : "3574feba-646d-4735-83c4-66f657e52517",
  "runId" : "38a78903-9e55-4440-ad81-50b591e4746c",
  "name" : "STREAMING_QUERY_NAME_UNIQUE",
  "timestamp" : "2022-10-31T20:09:30.455Z",
  "batchId" : 1377,
  "numInputRows" : 687,
  "inputRowsPerSecond" : 32.13433743393049,
  "processedRowsPerSecond" : 34.067241892293964,
  "sources": [
    {}, // source 1
    {}, // source 2...
  ],
  "sink": {},
  // info about time it takes to complete stages of micro-batch exec process
  "durationMs": {},
  // info about event time value seen in data in the micro-batch.
  "eventTime": {},
  "stateOperators": [ // info of stateful operations and aggregations
    {},
    {}
  ],

}
----


=== Deploying

. One cluster per stream
. Multiplex many streams on a single cluster
.. Pros
... Better cluster utilization
... Potential delta cache re-use
.. Cons
... Driver becomes a bottleneck
... Determining how many is difficult
... Load balancing streams across clusters also difficult

----
What causes bottlenecks in driver in multiplexing many streams on same cluster?
----
[start=1]
. Locks
.. JSON Serialization of offsets in streaming (Jackson)
.. Scala compiler (Encoder creation)
.. Hadoop Configurations (java.util.Properties)
.. Whole Stage Codegen (ClassLoader.loadClass)
. Garbage Collection


=== Streaming Kafka Integration

----
groupId = org.apache.spark
artifactId = spark-sql-kafka-0-10_2.12
----


==== Read
. Structured Streaming does not commit offset back to Kafka.
It manages partition -> offset internally by checkpointing them.
. Checkpointing process is not in `KafkaSource`, rather in Spark streaming core classes.
It uses offsets provided by KafkaSource to checkpoint the streaming job state.


----
// Subscribe to 1 topic
val df = spark
  .readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "host1:port1,host2:port2")
  .option("subscribe", "topic1")
  .load()
df.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)")
  .as[(String, String)]

// Subscribe to multiple topics, with headers
val df = spark
  .readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "host1:port1,host2:port2")
  .option("subscribe", "topic1,topic2")
  .option("includeHeaders", "true")
  .load()
df.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)", "headers")
  .as[(String, String, Array[(String, Array[Byte])])]
----

Each row has following schema

. key (binary)
. value (binary)
. topic (string)
. partition (int)
. offset (long)
. timestamp (timestamp) -> producer-set or log-append time (see details below)
. timestampType (int)
. headers (optional) (array)

`Timestamp`

* timestamp in a ProducerRecord can be set by either the producer or the broker, depending on the configuration of the topic.
* If the topic is configured to use `CreateTime`, the timestamp provided by the producer will be used by the broker.
* if the topic is configured to use `LogAppendTime`, the broker will overwrite the timestamp with its local time when appending the message to its log.
* timestamp is a millisecond-precision value and can be set as a string in the ProducerRecord constructor


Sequence of Interactions
[start=1]
1. `Source Creation`: When a query is defined using DataFrameReader.format("kafka"), Spark internally uses KafkaSourceProvider to instantiate the appropriate source based on the query's execution mode (micro-batch or continuous).
2. `Offset Fetching`: At the start of each micro-batch (or continuously in the case of continuous processing), KafkaSource or KafkaContinuousReader uses KafkaOffsetReader to query Kafka for the latest available offsets for the subscribed topics and partitions.
3. `Data Fetching`: With the start and end offsets determined, Spark then uses the Kafka consumer API (KafkaConsumer) to fetch the records from Kafka. In micro-batch mode, this happens for each batch. In continuous mode, this happens continuously.
4. `DataFrame Conversion`: The fetched records are converted into a DataFrame, with each Kafka record becoming a row in the DataFrame. This involves deserializing the key, value, and other metadata from each Kafka record.
5. `Query Execution`: The DataFrame is then processed according to the user-defined query operations (e.g., transformations, aggregations). This processing can involve multiple Spark executors depending on the query and cluster configuration.\
6. `Checkpointing`: Throughout this process, Spark Structured Streaming maintains checkpoint information, including offsets and query state, to ensure fault tolerance and allow queries to be restarted from where they left off in case of failure.

https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html#kafka-specific-configurations[Kafka optional configs]
[start=1]
. enable.auto.commit=false
. startingTimestamp
. startingOffsetsByTimestamp
. startingOffsets
. endingTimestamp
. endingOffsetsByTimestamp
. endingOffsets
. failOnDataLoss
. kafkaConsumer.pollTimeoutMs, default 2 minutes
. fetchOffset.numRetries
. fetchOffset.retryIntervalMs
. maxOffsetsPerTrigger
. minOffsetsPerTrigger
. maxTriggerDelay
. minPartitions
. groupIdPrefix
. kafka.group.id
. includeHeaders
. startingOffsetsByTimestampStrategy

Source code

. https://github.com/apache/spark/blob/master/connector/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala[spark/sql/kafka010/KafkaSource.scala]
. https://github.com/apache/spark/blob/master/connector/kafka-0-10-sql/src/test/scala/org/apache/spark/sql/kafka010/KafkaMicroBatchSourceSuite.scala[KafkaMicroBatchSourceSuite.scala]

==== Write

----
// Write key-value data from a DataFrame to a specific Kafka topic specified in an option
val ds = df
  .selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)")
  .writeStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "host1:port1,host2:port2")
  .option("topic", "topic1")
  .start()
----

* writing to Kafka in SS support only `at least once`
* `exactly once` is not supported due to reasons
** Kafka's producer only supports at-least-once delivery semantics out of the box via simple ACKs after writes.
** To get exactly-once guarantees, the producer needs to use more advanced features like idempotent writes and transactions.
** While the Kafka producer in Spark could support these, Structured Streaming was not designed/implemented to manage idempotent/transactional state across restarts or failed tasks.
** The micro-batch model of processing does not maintain exactly-once ordering guarantees even with transactions, due to potential retries.

== References
[start=1]
. https://www.youtube.com/watch?v=uP9bpaNvrvM&t[Video, Productizing Structured Streaming Jobs]
. Shuffle
.. https://cwiki.apache.org/confluence/display/SPARK/Shuffle+Internals
.. https://0x0fff.com/spark-architecture-shuffle/
.. https://people.eecs.berkeley.edu/~kubitron/courses/cs262a-F13/projects/reports/project16_report.pdf[Paper - xOptimizing Shuffle Performance in Spark]
.. https://issues.apache.org/jira/browse/SPARK-7081[Tungsten's sort idea]

. Optimization
.. https://developer.ibm.com/blogs/spark-performance-optimization-guidelines/[IBM Spark performance optimization guidelines]
.. https://www.youtube.com/watch?v=daXEp4HmS-E[Youtube, Apache Spark Core—Deep Dive—Proper Optimization, Daniel Tomes, Databricks]


